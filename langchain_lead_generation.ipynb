{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:06.789948Z",
     "start_time": "2024-11-25T08:25:06.784436Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_cohere import ChatCohere, CohereEmbeddings\n",
    "import pandas as pd \n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Load Dataset\n",
   "id": "74029e022bc9bf5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c8728185c9cfb066"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:06.803944Z",
     "start_time": "2024-11-25T08:25:06.789948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_dataset = pd.read_csv(\"logic/data/customer_leads_agent_qa_data_csv.csv\", encoding='latin1')\n",
    "predefined_questions = qa_dataset[\"prompt_text\"].tolist()\n",
    "expected_responses = dict(zip(qa_dataset[\"prompt_text\"], qa_dataset[\"expected_response\"]))\n",
    "\n",
    "print(\"Sample Questions:\", predefined_questions[:9])\n",
    "print(\"Sample Responses:\", list(expected_responses.items())[:5])\n"
   ],
   "id": "d02d343fbbdced4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Questions: ['\"What unique value do they offer?\"', '\"Who is your target audience?\"', 'What\\'s your ideal customer profile?\"', '\"What regions are you targeting?\"', '\"Who are your primary competitors?\"', '\"What resources do you have available?\"', '\"What\\'s your estimated budget?\"', ' \"What\\'s  your expected timeline?\"', '\"How do you plan to differentiate from competitors?\"']\n",
      "Sample Responses: [('\"What unique value do they offer?\"', '\"They offer unique value in areas like [strengths].\"'), ('\"Who is your target audience?\"', '\"Our target audience is [demographic].\"'), ('What\\'s your ideal customer profile?\"', '\"Our ideal customer profile includes [attributes].\"'), ('\"What regions are you targeting?\"', '\"We\\'re focusing on regions like [location].\"'), ('\"Who are your primary competitors?\"', '\"Our competitors include [names].\"')]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Generate Embeddings for Predefined Queries",
   "id": "8621502738780280"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.061945Z",
     "start_time": "2024-11-25T08:25:06.831534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model = CohereEmbeddings(cohere_api_key=\"QTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\", model=\"embed-english-light-v3.0\")\n",
    "vector_store = FAISS.from_texts(predefined_questions, embedding_model)\n"
   ],
   "id": "e8739c8afc0d2960",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.071155Z",
     "start_time": "2024-11-25T08:25:08.068645Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "66734fb07095608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3: Define Required Fields and Memory State",
   "id": "2cb63afdac14e3ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.081446Z",
     "start_time": "2024-11-25T08:25:08.077369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define required fields\n",
    "REQUIRED_FIELDS = [\"company_size\", \"industry\", \"location\", \"job_roles\"]\n",
    "\n",
    "# Initialize memory state\n",
    "memory_state = {\n",
    "    \"conversation\": [],  # Tracks user-agent interactions\n",
    "    \"extracted_data\": {field: None for field in REQUIRED_FIELDS},  # Stores field values\n",
    "    \"missing_fields\": REQUIRED_FIELDS[:],  # Tracks fields yet to be collected\n",
    "}\n",
    "\n",
    "print(\"Initialized Memory State:\", json.dumps(memory_state, indent=4))\n"
   ],
   "id": "ebd161fda5b1b186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Memory State: {\n",
      "    \"conversation\": [],\n",
      "    \"extracted_data\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": null\n",
      "    },\n",
      "    \"missing_fields\": [\n",
      "        \"company_size\",\n",
      "        \"industry\",\n",
      "        \"location\",\n",
      "        \"job_roles\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Define Functions",
   "id": "b0c3e37b25afd606"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.100723Z",
     "start_time": "2024-11-25T08:25:08.096657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dynamic_prompt(user_input, missing_fields):\n",
    "    \"\"\"\n",
    "    Generates a prompt for the LLM to extract the missing fields from user input.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    # Role\n",
    "    You are a Data Extraction Agent.\n",
    "\n",
    "    # Objective\n",
    "    Extract the following details from the user input: {', '.join(missing_fields)}.\n",
    "\n",
    "    # Context\n",
    "    The information extracted will help populate a structured memory state for a business analysis task.\n",
    "\n",
    "    # Input\n",
    "    User Input: {user_input}\n",
    "\n",
    "    # Response Format (JSON):\n",
    "    {{\n",
    "        \"company_size\": null or \"value\",\n",
    "        \"industry\": null or \"value\",\n",
    "        \"location\": null or \"value\",\n",
    "        \"job_roles\": null or [\"list of roles\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ],
   "id": "f27409e407369d22",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.112747Z",
     "start_time": "2024-11-25T08:25:08.108350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_memory_with_response(memory_state, extracted_data):\n",
    "    \"\"\"\n",
    "    Updates the memory state with the extracted fields and removes filled fields from missing_fields.\n",
    "    \"\"\"\n",
    "    for field, value in extracted_data.items():\n",
    "        if field in memory_state[\"missing_fields\"] and value:  # Only update if field is missing and value is valid\n",
    "            memory_state[\"extracted_data\"][field] = value\n",
    "            memory_state[\"missing_fields\"].remove(field)\n",
    "    return memory_state\n"
   ],
   "id": "dd517e4896e15749",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.122792Z",
     "start_time": "2024-11-25T08:25:08.118905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_next_field_prompt(memory_state):\n",
    "    \"\"\"\n",
    "    Returns the next prompt for the missing field.\n",
    "    \"\"\"\n",
    "    if memory_state[\"missing_fields\"]:\n",
    "        next_field = memory_state[\"missing_fields\"][0]\n",
    "        field_prompts = {\n",
    "            \"company_size\": \"What is the size of the companies you're targeting?\",\n",
    "            \"industry\": \"What industry are you targeting?\",\n",
    "            \"location\": \"Where are these companies located?\",\n",
    "            \"job_roles\": \"What roles or job titles are you targeting?\"\n",
    "        }\n",
    "        return field_prompts.get(next_field, \"Please provide more details.\")\n",
    "    return \"All required information has been collected.\"\n"
   ],
   "id": "1c50036e425e5f62",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Field Extraction Using LLM",
   "id": "bc386c64fc8dff92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.132552Z",
     "start_time": "2024-11-25T08:25:08.128561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_user_fields(user_input, missing_fields, model):\n",
    "    \"\"\"\n",
    "    Uses the LLM model to extract fields based on user input and missing fields.\n",
    "    Handles structured responses like AIMessage.\n",
    "    \"\"\"\n",
    "    prompt = create_dynamic_prompt(user_input, missing_fields)\n",
    "    try:\n",
    "        # Get the raw response from the model\n",
    "        raw_response = model.predict(prompt)\n",
    "        \n",
    "        print(f'raw_response: {raw_response}')\n",
    "        \n",
    "        # Extract the string content\n",
    "        response = raw_response.content if hasattr(raw_response, 'content') else raw_response\n",
    "        \n",
    "        # Parse the response as JSON\n",
    "        extracted_data = json.loads(response)\n",
    "        return extracted_data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON response: {e}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {}\n"
   ],
   "id": "9dc59a2fcc48d4be",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.141536Z",
     "start_time": "2024-11-25T08:25:08.138726Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "29a045b2c531f8b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.151508Z",
     "start_time": "2024-11-25T08:25:08.147351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def query_matching(user_query, vector_store, expected_responses, threshold=0.75):\n",
    "#     \"\"\"\n",
    "#     Matches a user query to the closest predefined question using vector embeddings.\n",
    "# \n",
    "#     Args:\n",
    "#         user_query (str): The query from the user.\n",
    "#         vector_store (FAISS): Vector store containing embeddings of predefined questions.\n",
    "#         expected_responses (dict): Mapping of predefined questions to their responses.\n",
    "#         threshold (float): Minimum similarity score to consider a match.\n",
    "# \n",
    "#     Returns:\n",
    "#         str: The matched response or a fallback response if no match is found.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Perform similarity search\n",
    "#         matches = vector_store.similarity_search_with_score(user_query, k=1)\n",
    "#         \n",
    "#         if not matches:\n",
    "#             return \"Sorry, I couldn't find a relevant match for your query.\"\n",
    "#         \n",
    "#         # Retrieve the best match and its similarity score\n",
    "#         best_match, score = matches[0]  # (Document, Score)\n",
    "#         \n",
    "#         if score >= threshold:\n",
    "#             matched_question = best_match.page_content\n",
    "#             return expected_responses.get(matched_question, \"No predefined response found.\")\n",
    "#         else:\n",
    "#             return \"Sorry, your query doesn't closely match any known question.\"\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during query matching: {e}\")\n",
    "#         return \"An error occurred while processing your query.\"\n"
   ],
   "id": "2c42c4e033d55f9b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.163438Z",
     "start_time": "2024-11-25T08:25:08.160312Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "da00108a196d6649",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.190830Z",
     "start_time": "2024-11-25T08:25:08.188953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def query_matching(user_input, vector_store, expected_responses):\n",
    "#     match = vector_store.similarity_search(user_input, k=1)\n",
    "#     if match:\n",
    "#         question = match[0].page_content\n",
    "#         response = expected_responses.get(question, \"No predefined response found.\")\n",
    "#         return response\n",
    "#     return \"Sorry, your query doesn't closely match any known question.\"\n"
   ],
   "id": "14b0b1f97d6a99c1",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.196290Z",
     "start_time": "2024-11-25T08:25:08.192854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def handle_greetings(user_input):\n",
    "    \"\"\"Detect greetings and return an appropriate response.\"\"\"\n",
    "    greetings = [\"hello\", \"hi\", \"hey\", \"greetings\"]\n",
    "    if user_input.lower() in greetings:\n",
    "        return \"Welcome! Feel free to ask questions or provide details.\"\n",
    "    return None\n"
   ],
   "id": "c98ddc62c4e2002d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.208048Z",
     "start_time": "2024-11-25T08:25:08.202727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_matching(user_input, vector_store, expected_responses, model, similarity_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Matches user input against the vector store and validates the similarity score.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The user's input query.\n",
    "        vector_store (VectorStore): The vector database containing the QA dataset.\n",
    "        expected_responses (dict): A mapping of questions to responses.\n",
    "        model (ChatOpenAI): The AI model instance for generating responses.\n",
    "        similarity_threshold (float): Minimum similarity score to consider a match valid.\n",
    "        \n",
    "    Returns:\n",
    "        str: The appropriate response or a default fallback.\n",
    "    \"\"\"\n",
    "    # Perform similarity search\n",
    "    matches = vector_store.similarity_search_with_score(user_input, k=1)\n",
    "    if matches:\n",
    "        match, score = matches[0]\n",
    "        print(f\"DEBUG: Match: {match.page_content}, Score: {score}\")\n",
    "\n",
    "        # Check if the similarity score exceeds the threshold\n",
    "        if score >= similarity_threshold:\n",
    "            question = match.page_content\n",
    "            response = expected_responses.get(question, \"No predefined response found.\")\n",
    "            \n",
    "            # Reformulate the response dynamically\n",
    "            reformulated_response = model.predict(\n",
    "                f\"Reformulate the following response to make it dynamic and engaging: {response}\"\n",
    "            )\n",
    "            return reformulated_response\n",
    "        else:\n",
    "            print(\"DEBUG: Low similarity score. Fallback to default response.\")\n",
    "    \n",
    "    # Default fallback for no match or low confidence\n",
    "    return \"I'm sorry, I couldn't find a direct answer. Can you provide more details about your request?\"\n"
   ],
   "id": "f423883d070f87c5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.216696Z",
     "start_time": "2024-11-25T08:25:08.215231Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aaa8f3e4ca8d1f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.226584Z",
     "start_time": "2024-11-25T08:25:08.222796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_dynamic_guidance(user_input, model):\n",
    "    prompt = f\"\"\"\n",
    "    User Request: {user_input}\n",
    "    You are an expert assistant for lead generation. Generate a detailed, step-by-step guide for generating a list of leads, including enrichment and refinement steps.\n",
    "    \"\"\"\n",
    "    response = model.predict(prompt)\n",
    "    return response"
   ],
   "id": "2004afeff9a9d249",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 5: Feedback Loop for Iterative Interaction\n",
   "id": "269f90d80c919af9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.239595Z",
     "start_time": "2024-11-25T08:25:08.236546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_agent_response(response):\n",
    "    \"\"\"Extracts and formats the model's response content.\"\"\"\n",
    "    if isinstance(response, dict) and \"content\" in response:\n",
    "        return response[\"content\"]\n",
    "    return str(response)"
   ],
   "id": "c220f6e5b151d436",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:08.254793Z",
     "start_time": "2024-11-25T08:25:08.247837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5: Chat Function\n",
    "def chat_with_fallback(model, memory_state, vector_store, expected_responses):\n",
    "    print(\"Agent: Welcome! Feel free to ask questions or provide details.\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        \n",
    "        # Check for exit commands\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"done\"]:\n",
    "            print(\"Agent: Thank you for the information. Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        # Check for empty input\n",
    "        if not user_input.strip():\n",
    "            print(\"Agent: I didn't catch that. Could you please repeat?\")\n",
    "            continue\n",
    "        \n",
    "        # Check for greetings\n",
    "        greeting_response = handle_greetings(user_input)\n",
    "        if greeting_response:\n",
    "            print(\"Agent:\", greeting_response)\n",
    "            continue\n",
    "        \n",
    "        # 2 - check for a new conversation\n",
    "        if not memory_state.get('conversation_started', False):\n",
    "            print(\"Agent: Starting a new conversation. Cleaning memory...\")\n",
    "            memory_state = {\n",
    "                \"conversation_started\": True,\n",
    "                \"missing_fields\": [\"company_size\", \"industry\", \"location\", \"job_roles\"],\n",
    "                \"extracted_data\": {}\n",
    "            }\n",
    " \n",
    "                # Focus on missing fields\n",
    "        if memory_state[\"missing_fields\"]:\n",
    "            print(\"Agent:\", get_next_field_prompt(memory_state))\n",
    "            extracted_data = extract_user_fields(user_input, memory_state[\"missing_fields\"], model)\n",
    "            memory_state = update_memory_with_response(memory_state, extracted_data)\n",
    "            \n",
    "            if not memory_state[\"missing_fields\"]:\n",
    "                print(\"Agent: All required information has been collected.\")\n",
    "                break\n",
    "            continue\n",
    " \n",
    "        # Query Matching\n",
    "        response = query_matching(user_input, vector_store, expected_responses, model)\n",
    "        if \"Sorry\" not in response:  # Valid match\n",
    "            print(\"Agent:\", clean_agent_response(response))\n",
    "            continue\n",
    "            \n",
    "        # If a response is found, print it and break the loop\n",
    "        dynamic_response = generate_dynamic_guidance(user_input, model)\n",
    "        print(\"Agent:\", clean_agent_response(dynamic_response))\n",
    "\n",
    "        # if memory_state[\"missing_fields\"]:\n",
    "        #     extracted_data = extract_user_fields(user_input, memory_state[\"missing_fields\"], model)\n",
    "        #     memory_state = update_memory_with_response(memory_state, extracted_data)\n",
    "        #     print(\"Agent: I have updated your details.\")\n",
    "        #     if not memory_state[\"missing_fields\"]:\n",
    "        #         print(\"Agent: All required information has been collected. Moving to the next steps.\")\n",
    "        #         break\n",
    "        #     else: \n",
    "        #         print(\"Agent: Please provide the following information:\", memory_state[\"missing_fields\"])\n",
    "        #         continue\n",
    "        #         \n",
    "        # # If no matching response or missing fields\n",
    "        # print(\"Agent: I didn't understand that. Can you clarify?\")\n"
   ],
   "id": "daeaf9abbc23885c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 6: Initialize Language Model and Start Interaction",
   "id": "fb6161885a637621"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:25:11.275015Z",
     "start_time": "2024-11-25T08:25:08.262071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Initialize Model and Start Chat\n",
    "model = ChatCohere(cohere_api_key=\"QTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\", temperature=0.5)\n",
    "result = chat_with_fallback(model, memory_state, vector_store, expected_responses)\n",
    "\n",
    "print(f\"Chat Completed -  result: {result}\")\n",
    "    "
   ],
   "id": "5cf768e286b4c463",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Welcome! Feel free to ask questions or provide details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Step 6: Initialize Model and Start Chat\u001B[39;00m\n\u001B[0;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m ChatCohere(cohere_api_key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\u001B[39m\u001B[38;5;124m\"\u001B[39m, temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mchat_with_fallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvector_store\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexpected_responses\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChat Completed -  result: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[22], line 5\u001B[0m, in \u001B[0;36mchat_with_fallback\u001B[1;34m(model, memory_state, vector_store, expected_responses)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAgent: Welcome! Feel free to ask questions or provide details.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m----> 5\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mUser: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Check for exit commands\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_input\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
