{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:15.939221Z",
     "start_time": "2024-11-25T06:09:11.333217Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_cohere import ChatCohere, CohereEmbeddings\n",
    "import pandas as pd \n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Load Dataset\n",
   "id": "74029e022bc9bf5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c8728185c9cfb066"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:15.981540Z",
     "start_time": "2024-11-25T06:09:15.959875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_dataset = pd.read_csv(\"customer_leads_agent_qa_data_csv.csv\")\n",
    "predefined_questions = qa_dataset[\"prompt_text\"].tolist()\n",
    "expected_responses = dict(zip(qa_dataset[\"prompt_text\"], qa_dataset[\"expected_response\"]))\n",
    "\n",
    "print(\"Sample Questions:\", predefined_questions[:5])\n",
    "print(\"Sample Responses:\", list(expected_responses.items())[:5])\n"
   ],
   "id": "d02d343fbbdced4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Questions: ['\"What unique value do they offer?\"', '\"Who is your target audience?\"', 'What\\'s your ideal customer profile?\"', '\"What regions are you targeting?\"', '\"Who are your primary competitors?\"']\n",
      "Sample Responses: [('\"What unique value do they offer?\"', '\"They offer unique value in areas like [strengths].\"'), ('\"Who is your target audience?\"', '\"Our target audience is [demographic].\"'), ('What\\'s your ideal customer profile?\"', '\"Our ideal customer profile includes [attributes].\"'), ('\"What regions are you targeting?\"', '\"We\\'re focusing on regions like [location].\"'), ('\"Who are your primary competitors?\"', '\"Our competitors include [names].\"')]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Generate Embeddings for Predefined Queries",
   "id": "8621502738780280"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.755761Z",
     "start_time": "2024-11-25T06:09:16.707028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model = CohereEmbeddings(cohere_api_key=\"QTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\", model=\"embed-english-light-v3.0\")\n",
    "vector_store = FAISS.from_texts(predefined_questions, embedding_model)\n"
   ],
   "id": "e8739c8afc0d2960",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.765855Z",
     "start_time": "2024-11-25T06:09:18.763759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "66734fb07095608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3: Define Required Fields and Memory State",
   "id": "2cb63afdac14e3ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.779214Z",
     "start_time": "2024-11-25T06:09:18.775676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define required fields\n",
    "REQUIRED_FIELDS = [\"company_size\", \"industry\", \"location\", \"job_roles\"]\n",
    "\n",
    "# Initialize memory state\n",
    "memory_state = {\n",
    "    \"conversation\": [],  # Tracks user-agent interactions\n",
    "    \"extracted_data\": {field: None for field in REQUIRED_FIELDS},  # Stores field values\n",
    "    \"missing_fields\": REQUIRED_FIELDS[:],  # Tracks fields yet to be collected\n",
    "}\n",
    "\n",
    "print(\"Initialized Memory State:\", json.dumps(memory_state, indent=4))\n"
   ],
   "id": "ebd161fda5b1b186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Memory State: {\n",
      "    \"conversation\": [],\n",
      "    \"extracted_data\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": null\n",
      "    },\n",
      "    \"missing_fields\": [\n",
      "        \"company_size\",\n",
      "        \"industry\",\n",
      "        \"location\",\n",
      "        \"job_roles\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Define Functions",
   "id": "b0c3e37b25afd606"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.809667Z",
     "start_time": "2024-11-25T06:09:18.806652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dynamic_prompt(user_input, missing_fields):\n",
    "    \"\"\"\n",
    "    Generates a prompt for the LLM to extract the missing fields from user input.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    # Role\n",
    "    You are a Data Extraction Agent.\n",
    "\n",
    "    # Objective\n",
    "    Extract the following details from the user input: {', '.join(missing_fields)}.\n",
    "\n",
    "    # Context\n",
    "    The information extracted will help populate a structured memory state for a business analysis task.\n",
    "\n",
    "    # Input\n",
    "    User Input: {user_input}\n",
    "\n",
    "    # Response Format (JSON):\n",
    "    {{\n",
    "        \"company_size\": null or \"value\",\n",
    "        \"industry\": null or \"value\",\n",
    "        \"location\": null or \"value\",\n",
    "        \"job_roles\": null or [\"list of roles\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ],
   "id": "f27409e407369d22",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.821145Z",
     "start_time": "2024-11-25T06:09:18.817662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_memory_with_response(memory_state, extracted_data):\n",
    "    \"\"\"\n",
    "    Updates the memory state with the extracted fields and removes filled fields from missing_fields.\n",
    "    \"\"\"\n",
    "    for field, value in extracted_data.items():\n",
    "        if field in memory_state[\"missing_fields\"] and value:  # Only update if field is missing and value is valid\n",
    "            memory_state[\"extracted_data\"][field] = value\n",
    "            memory_state[\"missing_fields\"].remove(field)\n",
    "    return memory_state\n"
   ],
   "id": "dd517e4896e15749",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Field Extraction Using LLM",
   "id": "bc386c64fc8dff92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.832614Z",
     "start_time": "2024-11-25T06:09:18.828815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_user_fields(user_input, missing_fields, model):\n",
    "    \"\"\"\n",
    "    Uses the LLM model to extract fields based on user input and missing fields.\n",
    "    Handles structured responses like AIMessage.\n",
    "    \"\"\"\n",
    "    prompt = create_dynamic_prompt(user_input, missing_fields)\n",
    "    try:\n",
    "        # Get the raw response from the model\n",
    "        raw_response = model.predict(prompt)\n",
    "        \n",
    "        print(f'raw_response: {raw_response}')\n",
    "        \n",
    "        # Extract the string content\n",
    "        response = raw_response.content if hasattr(raw_response, 'content') else raw_response\n",
    "        \n",
    "        # Parse the response as JSON\n",
    "        extracted_data = json.loads(response)\n",
    "        return extracted_data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON response: {e}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {}\n"
   ],
   "id": "9dc59a2fcc48d4be",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.841595Z",
     "start_time": "2024-11-25T06:09:18.839572Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "29a045b2c531f8b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:18.852675Z",
     "start_time": "2024-11-25T06:09:18.847811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_matching(user_query, vector_store, expected_responses, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Matches a user query to the closest predefined question using vector embeddings.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The query from the user.\n",
    "        vector_store (FAISS): Vector store containing embeddings of predefined questions.\n",
    "        expected_responses (dict): Mapping of predefined questions to their responses.\n",
    "        threshold (float): Minimum similarity score to consider a match.\n",
    "\n",
    "    Returns:\n",
    "        str: The matched response or a fallback response if no match is found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Perform similarity search\n",
    "        matches = vector_store.similarity_search_with_score(user_query, k=1)\n",
    "        \n",
    "        if not matches:\n",
    "            return \"Sorry, I couldn't find a relevant match for your query.\"\n",
    "        \n",
    "        # Retrieve the best match and its similarity score\n",
    "        best_match, score = matches[0]  # (Document, Score)\n",
    "        \n",
    "        if score >= threshold:\n",
    "            matched_question = best_match.page_content\n",
    "            return expected_responses.get(matched_question, \"No predefined response found.\")\n",
    "        else:\n",
    "            return \"Sorry, your query doesn't closely match any known question.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error during query matching: {e}\")\n",
    "        return \"An error occurred while processing your query.\"\n"
   ],
   "id": "2c42c4e033d55f9b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 5: Feedback Loop for Iterative Interaction\n",
   "id": "269f90d80c919af9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:28:04.296291Z",
     "start_time": "2024-11-25T06:28:04.290746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5: Chat Function\n",
    "def chat_with_fallback(model, memory_state, vector_store, expected_responses):\n",
    "    print(\"Agent: Welcome! Feel free to ask questions or provide details.\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"done\"]:\n",
    "            print(\"Agent: Thank you for the information. Goodbye!\")\n",
    "            break\n",
    "        if not user_input.strip():\n",
    "            print(\"Agent: I didn't catch that. Could you please repeat?\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # 2 - check for a new conversation\n",
    "        if not memory_state.get('conversation_started', False):\n",
    "            print(\"Agent: Starting a new conversation. Cleaning memory...\")\n",
    "            memory_state = {\n",
    "                \"conversation_started\": True,\n",
    "                \"missing_fields\": [\"company_size\", \"industry\", \"location\", \"job_roles\"],\n",
    "                \"extracted_data\": {}\n",
    "            }\n",
    " \n",
    "        \n",
    "        # Always check the response using query_matching\n",
    "        response = query_matching(user_input, vector_store, expected_responses)\n",
    "        \n",
    "        if response != \"Sorry, your query doesn't closely match any known question.\":\n",
    "            print(\"Agent:\", response)\n",
    "            print(\"Agent: I hope this answers your question. Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        # If a response is found, print it and break the loop\n",
    "        if response != \"Sorry, your query doesn't closely match any known question.\":\n",
    "            reformulated_response = model.predict(\n",
    "                f\"Reformulate the following response to make it dynamic and engaging: {response}\"\n",
    "            )\n",
    "            print(\"Agent:\", reformulated_response)\n",
    "            continue\n",
    "        \n",
    "        if memory_state[\"missing_fields\"]:\n",
    "            extracted_data = extract_user_fields(user_input, memory_state[\"missing_fields\"], model)\n",
    "            memory_state = update_memory_with_response(memory_state, extracted_data)\n",
    "            print(\"Agent: I have updated your details.\")\n",
    "            if not memory_state[\"missing_fields\"]:\n",
    "                print(\"Agent: All required information has been collected. Moving to the next steps.\")\n",
    "                break\n",
    "            else: \n",
    "                print(\"Agent: Please provide the following information:\", memory_state[\"missing_fields\"])\n",
    "                continue\n",
    "\n",
    "        # If no matching response or missing fields\n",
    "        print(\"Agent: I didn't understand that. Can you clarify?\")\n"
   ],
   "id": "daeaf9abbc23885c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 6: Initialize Language Model and Start Interaction",
   "id": "fb6161885a637621"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T06:09:28.371940Z",
     "start_time": "2024-11-25T06:09:18.879672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Initialize Model and Start Chat\n",
    "model = ChatCohere(cohere_api_key=\"QTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\", temperature=0.1)\n",
    "result = chat_with_fallback(model, memory_state, vector_store, expected_responses)\n",
    "\n",
    "print(f\"Chat Completed -  result: {result}\")\n",
    "    "
   ],
   "id": "5cf768e286b4c463",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Welcome! Feel free to ask questions or provide details.\n",
      "Agent: \"Available resources include [budget, team, technology].\"\n",
      "Agent: I hope this answers your question. Goodbye!\n",
      "Chat Completed -  result: None\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
