{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:43.576186Z",
     "start_time": "2024-11-25T11:54:43.571300Z"
    }
   },
   "source": [
    "import uuid\n",
    "import json\n",
    "\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver \n",
    "from langchain_cohere import ChatCohere"
   ],
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:43.977667Z",
     "start_time": "2024-11-25T11:54:43.587226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "model = ChatCohere(cohere_api_key=\"QTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\", temperature=0.1)\n"
   ],
   "id": "d0aa35a351c9876f",
   "outputs": [],
   "execution_count": 234
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f4f6897872ee368a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:43.987230Z",
     "start_time": "2024-11-25T11:54:43.984894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}"
   ],
   "id": "894814d127149d53",
   "outputs": [],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.001049Z",
     "start_time": "2024-11-25T11:54:43.992740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define workflow nodes\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)"
   ],
   "id": "44ac940177ebe59f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x20b291c9390>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 236
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9ea29d7e120b3712"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.019248Z",
     "start_time": "2024-11-25T11:54:44.007423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ],
   "id": "860fe2746b756235",
   "outputs": [],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.036901Z",
     "start_time": "2024-11-25T11:54:44.032377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate a unique thread ID for conversation management\n",
    "thread_id = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}"
   ],
   "id": "b667a121835cc171",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.046851Z",
     "start_time": "2024-11-25T11:54:44.044590Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2ee3ec69020547e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.055093Z",
     "start_time": "2024-11-25T11:54:44.052030Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ff2efbc311331491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.072708Z",
     "start_time": "2024-11-25T11:54:44.060465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "field_extraction_prompt = \"\"\"\n",
    "# Role\n",
    "\n",
    "You are a Data Extraction Agent.\n",
    "\n",
    "# Objective\n",
    "\n",
    "Your objective is to identify and extract specific business details from provided text, including industry, company size, location, and job roles. You should construct a full `user_info` dictionary with these details and indicate if there are any missing fields.\n",
    "\n",
    "# Context\n",
    "\n",
    "The extracted information will help provide structured business data from raw text inputs, which will support various business and analytical operations.\n",
    "\n",
    "# SOP\n",
    "\n",
    "1. Analyze the user-provided text in the variable user_input.\n",
    "\n",
    "2. Construct and return the following dictionary:\n",
    "\n",
    "{ \"company_size\": null or employee range (e.g., \"1-10\", \"500+\"), \"industry\": null or specific sector (e.g., \"Tech\", \"Healthcare\"), \"location\": null or specific location (e.g., city or country), \"job_roles\": [] or list of job titles mentioned }\n",
    "\n",
    "3. In addition to the dictionary, provide a list of fields that are still missing or mention that all fields are complete.\n",
    "\n",
    "# Examples\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "**Input:**\n",
    "\n",
    "\"Text describing a tech company based in New York with 200+ employees and titles like CEO, Data Scientist, and Product Manager.\"\n",
    "\n",
    "**Output:**\n",
    "\n",
    "{\n",
    "    \"user_info\": {\n",
    "        \"company_size\": \"200+\",\n",
    "        \"industry\": \"Tech\",\n",
    "        \"location\": \"New York\",\n",
    "        \"job_roles\": [\"CEO\", \"Data Scientist\", \"Product Manager\"]\n",
    "    },\n",
    "    \"missing_fields\": []\n",
    "}\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "**Input:**\n",
    "\n",
    "\"Description of a healthcare firm in Dubai without specific company size or job titles mentioned.\"\n",
    "\n",
    "**Output:**\n",
    "\n",
    "{\n",
    "    \"user_info\": {\n",
    "        \"company_size\": null,\n",
    "        \"industry\": \"Healthcare\",\n",
    "        \"location\": \"Dubai\",\n",
    "        \"job_roles\": []\n",
    "    },\n",
    "    \"missing_fields\": [\"company_size\", \"job_roles\"]\n",
    "}\n",
    "\n",
    "**Example 3:**\n",
    "\n",
    "**Input:**\n",
    "\n",
    "\"A small tech startup with less than 10 employees, located in San Francisco. The team includes a CEO and a CTO.\"\n",
    "\n",
    "**Output:**\n",
    "\n",
    "{\n",
    "    \"user_info\": {\n",
    "        \"company_size\": \"1-10\",\n",
    "        \"industry\": \"Tech\",\n",
    "        \"location\": \"San Francisco\",\n",
    "        \"job_roles\": [\"CEO\", \"CTO\"]\n",
    "    },\n",
    "    \"missing_fields\": []\n",
    "}\n",
    "\"\"\""
   ],
   "id": "d84b729eabeef5f3",
   "outputs": [],
   "execution_count": 239
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract user fields:\n",
   "id": "51261c569372d48a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.087019Z",
     "start_time": "2024-11-25T11:54:44.079626Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5fbdd77185121ec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.103745Z",
     "start_time": "2024-11-25T11:54:44.093098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "REQUIRED_FIELDS = {\"company_size\", \"industry\", \"job_roles\", \"location\"}\n",
    "\n",
    "# Global dictionary to keep track of extracted fields and missing fields\n",
    "recorded_fields = {\n",
    "    \"user_info\": {},\n",
    "    \"missing_fields\": list(REQUIRED_FIELDS)  # Initially, all fields are required\n",
    "}"
   ],
   "id": "73478c784817f89f",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.121807Z",
     "start_time": "2024-11-25T11:54:44.109882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_user_fields(message, model):\n",
    "    prompt = field_extraction_prompt + f\"\\nInput: {message}\\nResponse format (JSON): {{'company_size': '', 'industry': '', 'job_roles': '', 'location': ''}}\"\n",
    "        \n",
    "    try: \n",
    "        llm_response = model.predict(prompt) \n",
    "        llm_extracted_data = json.loads(llm_response)\n",
    "        print(llm_extracted_data)\n",
    "        return llm_extracted_data\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in template formatting: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to decode JSON response: {e}\")\n"
   ],
   "id": "903137cf2cfdec8f",
   "outputs": [],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:44.133924Z",
     "start_time": "2024-11-25T11:54:44.129774Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "27cb72ace8b69288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:46.153162Z",
     "start_time": "2024-11-25T11:54:44.139602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the extraction\n",
    "user_input = \"A startup\"\n",
    "extracted_data = extract_user_fields(user_input, model)\n",
    "\n",
    "print(\"Extracted Data:\", extracted_data)\n",
    "\n",
    "\n",
    "# Define the required fields\n",
    "required_fields = ['industry', 'company_size', 'location', 'job_roles']\n",
    "\n",
    "print(\"Missing Fields:\", extracted_data[\"missing_fields\"])\n"
   ],
   "id": "5a2d24e0fc0aa8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_info': {'company_size': None, 'industry': None, 'location': None, 'job_roles': []}, 'missing_fields': ['company_size', 'industry', 'location', 'job_roles']}\n",
      "Extracted Data: {'user_info': {'company_size': None, 'industry': None, 'location': None, 'job_roles': []}, 'missing_fields': ['company_size', 'industry', 'location', 'job_roles']}\n",
      "Missing Fields: ['company_size', 'industry', 'location', 'job_roles']\n"
     ]
    }
   ],
   "execution_count": 242
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:46.166705Z",
     "start_time": "2024-11-25T11:54:46.159200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Memory initialization\n",
    "memory_state = {\n",
    "    \"conversation\": [],\n",
    "    \"extracted_data\": {\"company_size\": None, \"industry\": None, \"job_roles\": None, \"location\": None},\n",
    "    \"missing_fields\": [\"company_size\", \"industry\", \"job_roles\", \"location\"],\n",
    "}\n",
    "\n",
    "def update_memory_with_response(llm_memory_state, llm_extracted_data):\n",
    "    for field, value in llm_extracted_data.items():\n",
    "        if value in llm_memory_state[\"extracted_data\"]:\n",
    "            llm_memory_state[\"extracted_data\"][field] = value\n",
    "            llm_memory_state[\"missing_fields\"].remove(field)\n",
    "    return llm_memory_state\n",
    "\n",
    "\n"
   ],
   "id": "805a060bc3255b5c",
   "outputs": [],
   "execution_count": 243
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:46.184266Z",
     "start_time": "2024-11-25T11:54:46.175193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dynamic_prompt(user_input, missing_fields):\n",
    "    prompt = f\"Extract the following details: {', '.join(missing_fields)}.\\n\"\n",
    "    prompt += f\"Input: {user_input}\\nResponse format (JSON): {{'company_size': '', 'industry': '', 'job_roles': '', 'location': ''}}\"\n",
    "    return prompt\n"
   ],
   "id": "ba1707b7f19327e6",
   "outputs": [],
   "execution_count": 244
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:46.195175Z",
     "start_time": "2024-11-25T11:54:46.192890Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5e1d30ecf5ec969",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:46.205746Z",
     "start_time": "2024-11-25T11:54:46.200922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def feedback_loop(model, memory_state):\n",
    "    \"\"\"Iterative dialog with the user to complete missing fields.\"\"\"\n",
    "    print(\"Agent: Let's gather some details about your target.\")\n",
    "    \n",
    "    while memory_state[\"missing_fields\"]:\n",
    "        missing_fields = memory_state[\"missing_fields\"]    \n",
    "    \n",
    "        dynamic_prompt = create_dynamic_prompt(\"\", missing_fields)\n",
    "\n",
    "        # Ask the user for the missing field\n",
    "        user_input = input(f\"Agent: Please provide details about {', '.join(missing_fields)}.\\nUser: \")\n",
    "        \n",
    "        # Update the prompt with user input\n",
    "        full_prompt = create_dynamic_prompt(user_input, missing_fields)\n",
    "\n",
    "        # Extract the user input\n",
    "        extracted_data = extract_user_fields(full_prompt, model)\n",
    "        \n",
    "        # Update the memory state\n",
    "        memory_state = update_memory_with_response(memory_state, extracted_data)\n",
    "        \n",
    "        # Log the conversation\n",
    "        memory_state[\"conversation\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "        memory_state[\"conversation\"].append({\"role\": \"agent\", \"content\": f\"Extracted: {extracted_data}\"})\n",
    "        print(\"Memory State:\", memory_state)\n",
    "        print(\"Agent: Thank you! All fields are complete.\")\n",
    "\n",
    "    return memory_state"
   ],
   "id": "f4ded6f865071fd7",
   "outputs": [],
   "execution_count": 245
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:46.843370Z",
     "start_time": "2024-11-25T11:54:46.220066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validation_prompt = create_dynamic_prompt(user_input, [\"company_size\", \"location\"])\n",
    "validation_response = model.predict(validation_prompt)"
   ],
   "id": "cb70eb81d1595d4a",
   "outputs": [],
   "execution_count": 246
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:48.166469Z",
     "start_time": "2024-11-25T11:54:46.849016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extracted_data = extract_user_fields(user_input, model)\n",
    "refined_query = create_dynamic_prompt(\"\", [\"industry\", \"location\"])"
   ],
   "id": "a5790afc7eb00e17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_info': {'company_size': None, 'industry': None, 'location': None, 'job_roles': []}, 'missing_fields': ['company_size', 'industry', 'location', 'job_roles']}\n"
     ]
    }
   ],
   "execution_count": 247
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query Matching and storage",
   "id": "ecd17c63b81b4fcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:48.178343Z",
     "start_time": "2024-11-25T11:54:48.173267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_matching(user_input, vector_store, expected_responses, model, similarity_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Matches user input against a vector store of predefined questions and handles fallbacks.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): The user's query or input.\n",
    "        vector_store (VectorStore): The vector store containing the QA dataset questions.\n",
    "        expected_responses (dict): A dictionary mapping questions to their expected responses.\n",
    "        model (ChatOpenAI): The AI model instance for generating reformulated responses.\n",
    "        similarity_threshold (float): The minimum similarity score to consider a match valid.\n",
    "\n",
    "    Returns:\n",
    "        str: A response for the user or a fallback message if no match is found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Perform similarity search\n",
    "        matches = vector_store.similarity_search_with_score(user_input, k=1)\n",
    "        if matches:\n",
    "            match, score = matches[0]\n",
    "            print(f\"DEBUG: Match Found: {match.page_content}, Similarity Score: {score}\")\n",
    "\n",
    "            # Step 2: Check if the similarity score meets the threshold\n",
    "            if score >= similarity_threshold:\n",
    "                matched_question = match.page_content\n",
    "                predefined_response = expected_responses.get(\n",
    "                    matched_question,\n",
    "                    \"I couldn't find a predefined response for this question.\"\n",
    "                )\n",
    "\n",
    "                # Step 3: Reformulate the response dynamically\n",
    "                reformulated_response = model.predict(\n",
    "                    f\"Reformulate the following response to make it more engaging: {predefined_response}\"\n",
    "                )\n",
    "                return reformulated_response.strip()\n",
    "\n",
    "        # Step 4: If no valid match, provide fallback guidance\n",
    "        print(\"DEBUG: No valid match found or low similarity score.\")\n",
    "        return \"I'm sorry, I couldn't find a direct answer. Could you provide more details about your request?\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in query_matching: {e}\")\n",
    "        return \"I'm sorry, something went wrong while processing your request.\"\n"
   ],
   "id": "f80330a0796fedec",
   "outputs": [],
   "execution_count": 248
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5cb9b56e28896749"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:49.145424Z",
     "start_time": "2024-11-25T11:54:48.184980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "qa_dataset = pd.read_csv('logic/data/customer_leads_agent_qa_data_csv.csv', delimiter=',', encoding='latin1').to_dict(orient='records')\n",
    "\n",
    "# Convert questions into embeddings\n",
    "embeddings = CohereEmbeddings(cohere_api_key=\"QTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\", model=\"embed-english-light-v3.0\" )\n",
    "\n",
    "questions = [item[\"prompt_text\"] for item in qa_dataset]\n",
    "vector_store = FAISS.from_texts(questions, embeddings)\n",
    "    \n",
    "# Map each vector to its expected response\n",
    "responses = {item[\"prompt_text\"]: item[\"expected_response\"] for item in qa_dataset}\n"
   ],
   "id": "fa896d452afe896e",
   "outputs": [],
   "execution_count": 249
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:50.223571Z",
     "start_time": "2024-11-25T11:54:49.151338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# User's input query\n",
    "user_query = \"What unique value do they offer?\"\n",
    "\n",
    "# Query matching\n",
    "response = query_matching(user_query, vector_store, responses, model, similarity_threshold=0.3)\n",
    "\n",
    "# Print the response\n",
    "print(\"Agent's Response:\", response)\n"
   ],
   "id": "b93c1cbfbb752dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Match Found: \"What unique value do they offer?\", Similarity Score: 0.7451424598693848\n",
      "Agent's Response: Looking to leverage their expertise in [strengths], this company brings a distinctive advantage to the table. Their capabilities in this area are truly remarkable and set them apart from the competition.\n"
     ]
    }
   ],
   "execution_count": 250
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:50.234461Z",
     "start_time": "2024-11-25T11:54:50.229518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_memory(current_memory, new_memory):\n",
    "    for key, value in new_memory.items():\n",
    "        if isinstance(value, dict) and key in current_memory:\n",
    "            # Recursive merge for nested dictionaries\n",
    "            merge_memory(current_memory[key], value)\n",
    "        else:\n",
    "            # Update scalar values or new keys\n",
    "            current_memory[key] = value"
   ],
   "id": "fcc2c1cb1c618145",
   "outputs": [],
   "execution_count": 251
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:50.244397Z",
     "start_time": "2024-11-25T11:54:50.240780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def handle_no_match(llm_memory_state, llm_model):\n",
    "#     \"\"\"Fallback to feedback loop when no match is found.\"\"\"\n",
    "#     print(\"Agent: I couldn't find a predefined match. Let's refine your query.\")\n",
    "#     llm_memory_state, llm_extracted_data = feedback_loop(memory_state=memory_state, model=llm_model)\n",
    "#     return llm_memory_state, llm_extracted_data\n"
   ],
   "id": "dec3fac87074e43a",
   "outputs": [],
   "execution_count": 252
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:50.255947Z",
     "start_time": "2024-11-25T11:54:50.250155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def model_driven_feedback_loop(fcn_user_input, fcn_memory_state, model):\n",
    "    \"\"\"\n",
    "    Handles feedback loop by using the model to manage memory and prompts dynamically.\n",
    "    \n",
    "    Args:\n",
    "        fcn_user_input (str): The current user input.\n",
    "        fcn_memory_state (dict): Dictionary containing collected data and missing fields.\n",
    "        model (ChatOpenAI): Language model instance.\n",
    "    \n",
    "    Returns:\n",
    "        updated_memory (dict): Updated memory state with new extracted data.\n",
    "        next_prompt (str): Next prompt for the user.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare memory for the prompt\n",
    "        memory_state_str = json.dumps(fcn_memory_state, indent=4)\n",
    "        updated_memory = fcn_memory_state.get(\"updated_memory\", {})\n",
    "        updated_memory_str = json.dumps(updated_memory, indent=4)\n",
    "\n",
    "        # Construct the prompt\n",
    "        prompt = f\"\"\"\n",
    "        Role: You are a Data Extraction Agent responsible for collecting specific business details iteratively. \n",
    "        # Objective\n",
    "        Your task is to:\n",
    "        1. Update the `memory_state` dictionary with any new information extracted from `user_input`.\n",
    "        2. Identify any fields still missing and construct a `next_prompt` to ask the user for these details.\n",
    "        3. If all required fields are complete, indicate this in the `next_prompt`.\n",
    "\n",
    "        # Memory State:\n",
    "        {memory_state_str}\n",
    "\n",
    "        # User Input:\n",
    "        {fcn_user_input}\n",
    "\n",
    "        # Response Format\n",
    "        Respond in the following JSON format:\n",
    "        {{\n",
    "            \"updated_memory\": {updated_memory_str},\n",
    "            \"next_prompt\": \"string\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Debugging: Print the constructed prompt\n",
    "        print(f\"Prompt sent to model: {prompt}\")\n",
    "        \n",
    "        # Generate the response\n",
    "        response = model.predict(prompt)\n",
    "        print(f\"Response from model: {response}\")\n",
    "\n",
    "        # Parse the response\n",
    "        response_data = json.loads(response)\n",
    "        \n",
    "        # Update memory\n",
    "        fcn_updated_memory = copy.deepcopy(fcn_memory_state)\n",
    "        merge_memory(fcn_updated_memory, response_data.get(\"updated_memory\", {}))\n",
    "        \n",
    "        \n",
    "        # Debugging: Check memory updates\n",
    "        print(\"Original memory state:\", json.dumps(fcn_memory_state, indent=4))\n",
    "        print(\"Response data:\", json.dumps(response_data, indent=4))\n",
    "        print(\"Updated memory state:\", json.dumps(fcn_updated_memory, indent=4))\n",
    "\n",
    "        # Get the next prompt\n",
    "        fcn_next_prompt = response_data.get(\"next_prompt\", \"All required fields are complete.\")\n",
    "\n",
    "        return fcn_updated_memory, fcn_next_prompt\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON response: {e}\")\n",
    "        return fcn_memory_state, \"An error occurred. Please try again.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return fcn_memory_state, \"An error occurred. Please try again.\""
   ],
   "id": "72a9aabc4061128e",
   "outputs": [],
   "execution_count": 253
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "30bb8145ca48851b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:50.264583Z",
     "start_time": "2024-11-25T11:54:50.261268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_inputs_example = [\n",
    "    \"I am targeting companies in San Francisco.\",\n",
    "    \"These companies should have 500+ employees.\",\n",
    "    \"I want to reach CTOs and Product Managers.\"\n",
    "]\n",
    "\n",
    "memory_state_example = {\n",
    "    \"updated_memory\": {\n",
    "        \"company_size\": None,\n",
    "        \"industry\": None,\n",
    "        \"location\": None,\n",
    "        \"job_roles\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ],
   "id": "7c51be243b1d34e",
   "outputs": [],
   "execution_count": 254
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "577eb830191912df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.165424Z",
     "start_time": "2024-11-25T11:54:50.270047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterative feedback loop\n",
    "for user_input in user_inputs_example:\n",
    "    memory_state_example, next_prompt = model_driven_feedback_loop(\n",
    "        fcn_user_input=user_input,\n",
    "        fcn_memory_state=memory_state_example,\n",
    "        model=model\n",
    "    )\n",
    "    print(f\"Agent: {next_prompt}\")\n",
    "    print(f\"Updated Memory State: {json.dumps(memory_state_example, indent=4)}\")\n",
    "    if \"All required fields are complete\" in next_prompt:\n",
    "        break\n"
   ],
   "id": "5c3b165deb504264",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt sent to model: \n",
      "        Role: You are a Data Extraction Agent responsible for collecting specific business details iteratively. \n",
      "        # Objective\n",
      "        Your task is to:\n",
      "        1. Update the `memory_state` dictionary with any new information extracted from `user_input`.\n",
      "        2. Identify any fields still missing and construct a `next_prompt` to ask the user for these details.\n",
      "        3. If all required fields are complete, indicate this in the `next_prompt`.\n",
      "\n",
      "        # Memory State:\n",
      "        {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    }\n",
      "}\n",
      "\n",
      "        # User Input:\n",
      "        I am targeting companies in San Francisco.\n",
      "\n",
      "        # Response Format\n",
      "        Respond in the following JSON format:\n",
      "        {\n",
      "            \"updated_memory\": {\n",
      "    \"company_size\": null,\n",
      "    \"industry\": null,\n",
      "    \"location\": null,\n",
      "    \"job_roles\": []\n",
      "},\n",
      "            \"next_prompt\": \"string\"\n",
      "        }\n",
      "        \n",
      "Response from model: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": \"San Francisco\",\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"next_prompt\": \"Great, we now have the location. Can you provide details about the industries and company sizes you are targeting? Also, what specific job roles are you interested in?\"\n",
      "}\n",
      "Original memory state: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    }\n",
      "}\n",
      "Response data: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": \"San Francisco\",\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"next_prompt\": \"Great, we now have the location. Can you provide details about the industries and company sizes you are targeting? Also, what specific job roles are you interested in?\"\n",
      "}\n",
      "Updated memory state: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": null,\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "Agent: Great, we now have the location. Can you provide details about the industries and company sizes you are targeting? Also, what specific job roles are you interested in?\n",
      "Updated Memory State: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": null,\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "Prompt sent to model: \n",
      "        Role: You are a Data Extraction Agent responsible for collecting specific business details iteratively. \n",
      "        # Objective\n",
      "        Your task is to:\n",
      "        1. Update the `memory_state` dictionary with any new information extracted from `user_input`.\n",
      "        2. Identify any fields still missing and construct a `next_prompt` to ask the user for these details.\n",
      "        3. If all required fields are complete, indicate this in the `next_prompt`.\n",
      "\n",
      "        # Memory State:\n",
      "        {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": null,\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "\n",
      "        # User Input:\n",
      "        These companies should have 500+ employees.\n",
      "\n",
      "        # Response Format\n",
      "        Respond in the following JSON format:\n",
      "        {\n",
      "            \"updated_memory\": {\n",
      "    \"company_size\": null,\n",
      "    \"industry\": null,\n",
      "    \"location\": null,\n",
      "    \"job_roles\": []\n",
      "},\n",
      "            \"next_prompt\": \"string\"\n",
      "        }\n",
      "        \n",
      "Response from model: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": \"500+ employees\",\n",
      "        \"industry\": null,\n",
      "        \"location\": \"San Francisco\",\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"next_prompt\": \"Please provide the industry type for these companies. If you have this information, please share the specific job roles or departments you are interested in.\"\n",
      "}\n",
      "Original memory state: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": null,\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "Response data: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": \"500+ employees\",\n",
      "        \"industry\": null,\n",
      "        \"location\": \"San Francisco\",\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"next_prompt\": \"Please provide the industry type for these companies. If you have this information, please share the specific job roles or departments you are interested in.\"\n",
      "}\n",
      "Updated memory state: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": \"500+ employees\",\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "Agent: Please provide the industry type for these companies. If you have this information, please share the specific job roles or departments you are interested in.\n",
      "Updated Memory State: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": \"500+ employees\",\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "Prompt sent to model: \n",
      "        Role: You are a Data Extraction Agent responsible for collecting specific business details iteratively. \n",
      "        # Objective\n",
      "        Your task is to:\n",
      "        1. Update the `memory_state` dictionary with any new information extracted from `user_input`.\n",
      "        2. Identify any fields still missing and construct a `next_prompt` to ask the user for these details.\n",
      "        3. If all required fields are complete, indicate this in the `next_prompt`.\n",
      "\n",
      "        # Memory State:\n",
      "        {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": \"500+ employees\",\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "\n",
      "        # User Input:\n",
      "        I want to reach CTOs and Product Managers.\n",
      "\n",
      "        # Response Format\n",
      "        Respond in the following JSON format:\n",
      "        {\n",
      "            \"updated_memory\": {\n",
      "    \"company_size\": null,\n",
      "    \"industry\": null,\n",
      "    \"location\": null,\n",
      "    \"job_roles\": []\n",
      "},\n",
      "            \"next_prompt\": \"string\"\n",
      "        }\n",
      "        \n",
      "Response from model: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": \"500+ employees\",\n",
      "        \"industry\": null,\n",
      "        \"location\": \"San Francisco\",\n",
      "        \"job_roles\": [\"CTO\", \"Product Manager\"]\n",
      "    },\n",
      "    \"next_prompt\": \"Please provide the industry type of the company you are targeting. Once I have this information, I will have all the required fields completed.\"\n",
      "}\n",
      "Original memory state: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": \"500+ employees\",\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": []\n",
      "}\n",
      "Response data: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": \"500+ employees\",\n",
      "        \"industry\": null,\n",
      "        \"location\": \"San Francisco\",\n",
      "        \"job_roles\": [\n",
      "            \"CTO\",\n",
      "            \"Product Manager\"\n",
      "        ]\n",
      "    },\n",
      "    \"next_prompt\": \"Please provide the industry type of the company you are targeting. Once I have this information, I will have all the required fields completed.\"\n",
      "}\n",
      "Updated memory state: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": \"500+ employees\",\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": [\n",
      "        \"CTO\",\n",
      "        \"Product Manager\"\n",
      "    ]\n",
      "}\n",
      "Agent: Please provide the industry type of the company you are targeting. Once I have this information, I will have all the required fields completed.\n",
      "Updated Memory State: {\n",
      "    \"updated_memory\": {\n",
      "        \"company_size\": null,\n",
      "        \"industry\": null,\n",
      "        \"location\": null,\n",
      "        \"job_roles\": []\n",
      "    },\n",
      "    \"company_size\": \"500+ employees\",\n",
      "    \"industry\": null,\n",
      "    \"location\": \"San Francisco\",\n",
      "    \"job_roles\": [\n",
      "        \"CTO\",\n",
      "        \"Product Manager\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 255
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4278b5e8a410195d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.177409Z",
     "start_time": "2024-11-25T11:54:55.171850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_with_model(model_fcn, memory_state_fcn):\n",
    "    \"\"\"\n",
    "    Simulates a chat between the user and the AI model using the model-driven feedback loop.\n",
    "    \n",
    "    Args:\n",
    "        model_fcn (ChatOpenAI): The AI model instance.\n",
    "        memory_state_fcn (dict): Tracks extracted data and missing fields.\n",
    "\n",
    "    Returns:\n",
    "        None: Continuously interacts with the user until all fields are collected.\n",
    "    \"\"\"\n",
    "    print(\"Agent: Let's gather the necessary details. Feel free to provide information step by step.\")\n",
    "    \n",
    "    debug_mode = True  # Set this flag to False in production    \n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "                 \n",
    "            if memory_state_fcn[\"missing_fields\"]:\n",
    "                next_prompt_fcn = f\"Please provide the {memory_state_fcn['missing_fields'][0]}.\"\n",
    "            else:\n",
    "                next_prompt_fcn = \"All required fields are complete. Do you need any further assistance?\"\n",
    " \n",
    "       \n",
    "            # Display the AI's next prompt to the user\n",
    "            # Display the AI's next prompt to the user\n",
    "            print(f\"Agent: {next_prompt_fcn}\")\n",
    "\n",
    "\n",
    "            # Get user input\n",
    "            user_input = input(\"User: \")\n",
    "            \n",
    "                        # Exit condition\n",
    "            if user_input.lower() in [\"exit\", \"quit\", \"done\"]:\n",
    "                print(\"Agent: Thank you for the information. Goodbye!\")\n",
    "                break\n",
    "                \n",
    "                \n",
    "            if not user_input.strip():\n",
    "                print(\"Agent: I didn't catch that. Could you provide more details?\")\n",
    "                continue\n",
    "\n",
    "            # Match the user query to a predefined response\n",
    "            response = query_matching(user_input, vector_store, responses)\n",
    "            \n",
    "            if response:\n",
    "                print(\"Agent:\", response)\n",
    "            else:\n",
    "                # Run the feedback loop with the user's input\n",
    "                memory_state_fcn, next_prompt_fcn = model_driven_feedback_loop(\n",
    "                    fcn_user_input=user_input,\n",
    "                    fcn_memory_state=memory_state_fcn,\n",
    "                    model=model_fcn\n",
    "                )\n",
    "        \n",
    "        \n",
    "            # Debugging: Log the updated memory state if debugging is enabled\n",
    "            if debug_mode:\n",
    "                print(f\"Updated Memory State: {json.dumps(memory_state_fcn, indent=4)}\")\n",
    "\n",
    "            # Check if all fields are complete\n",
    "            if \"All required fields are complete\" in next_prompt_fcn:\n",
    "                print(f\"Agent: {next_prompt_fcn}\")\n",
    "                print(f\"Final Memory State: {json.dumps(memory_state_fcn, indent=4)}\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Agent: I encountered an issue. Please try again.\")\n",
    "            break"
   ],
   "id": "14e36ad4228d95d1",
   "outputs": [],
   "execution_count": 256
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3883207902dece1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.187226Z",
     "start_time": "2024-11-25T11:54:55.183124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_agent():\n",
    "    \"\"\"\n",
    "    Initializes the model and memory state for the chat agent.\n",
    "    Returns:\n",
    "        model_fcn (ChatCohere): The AI model instance.\n",
    "        memory_state_fcn (dict): The initial memory state.\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model_fcn = ChatCohere(cohere_api_key=\"QTIAR07ZVhcAVAPrUTHQozivAbRFhmhdoWwPsclg\", temperature=0.1)\n",
    "\n",
    "    # Initialize memory state\n",
    "    memory_state_fcn = {\n",
    "        \"updated_memory\": {\n",
    "            \"company_size\": None,\n",
    "            \"industry\": None,\n",
    "            \"location\": None,\n",
    "            \"job_roles\": []\n",
    "        },\n",
    "        \"next_prompt\": \"How may I help you today?\"\n",
    "    }\n",
    "\n",
    "    return model_fcn, memory_state_fcn\n"
   ],
   "id": "7b0d93a8076834c6",
   "outputs": [],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.196698Z",
     "start_time": "2024-11-25T11:54:55.192875Z"
    }
   },
   "cell_type": "code",
   "source": "initial_memory_state = {\"missing_fields\": [\"user_name\"], \"next_prompt\": \"What is your name?\"}\n",
   "id": "73c5bb710b79a044",
   "outputs": [],
   "execution_count": 258
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f4c5fecee06d52c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.206964Z",
     "start_time": "2024-11-25T11:54:55.203977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if __name__ == \"__main__\":    \n",
    "#    chat_with_model(model_fcn=model, memory_state_fcn=initial_memory_state)\n"
   ],
   "id": "1efc81ac9e5dd9dd",
   "outputs": [],
   "execution_count": 259
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.216986Z",
     "start_time": "2024-11-25T11:54:55.213049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dynamic_prompt(field):\n",
    "    \"\"\"\n",
    "    Generates a dynamic prompt for the given field.\n",
    "    \"\"\"\n",
    "    prompts = {\n",
    "        \"company_size\": \"What is the size of the companies you're targeting? For example: 1-10, 50-200, 500+.\",\n",
    "        \"industry\": \"Which industry are you targeting? For example: Tech, Healthcare, or Finance.\",\n",
    "        \"location\": \"Where are these companies located? Provide a city, state, or country.\",\n",
    "        \"job_roles\": \"What roles or job titles are you targeting? For example: CTO, Product Manager.\"\n",
    "    }\n",
    "    return prompts.get(field, \"Please provide more details about the required field.\")\n"
   ],
   "id": "ca107cf51c2c56de",
   "outputs": [],
   "execution_count": 260
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.227125Z",
     "start_time": "2024-11-25T11:54:55.223086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_response(response, field):\n",
    "    \"\"\"\n",
    "    Validates user responses based on the field requirements.\n",
    "    \"\"\"\n",
    "    if field == \"company_size\" and not any(char.isdigit() for char in response):\n",
    "        return False\n",
    "    if field == \"location\" and len(response.split()) < 2:  # Example: Expect 'City, State'\n",
    "        return False\n",
    "    if field == \"job_roles\" and len(response.split(\",\")) < 1:  # Expect a list of roles\n",
    "        return False\n",
    "    return True"
   ],
   "id": "9c0e68de51b7a1fe",
   "outputs": [],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.236399Z",
     "start_time": "2024-11-25T11:54:55.232949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def suggest_next_steps():\n",
    "    \"\"\"\n",
    "    Suggests the next steps after all fields have been collected.\n",
    "    \"\"\"\n",
    "    print(\"Agent: Great! Here’s what you can do next:\")\n",
    "    print(\"- Use LinkedIn or Sales Navigator to search for companies matching these criteria.\")\n",
    "    print(\"- Enrich your lead data with contact details using tools like Hunter.io.\")\n",
    "    print(\"- Consolidate the results into a lead list for outreach.\")\n"
   ],
   "id": "bb18d2430defd154",
   "outputs": [],
   "execution_count": 262
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.245167Z",
     "start_time": "2024-11-25T11:54:55.241973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_memory():\n",
    "    \"\"\"\n",
    "    Resets the memory state to start a new conversation.\n",
    "    \"\"\"\n",
    "    global memory_state\n",
    "    memory_state = {\n",
    "        \"conversation_started\": False,\n",
    "        \"missing_fields\": [\"company_size\", \"industry\", \"location\", \"job_roles\"],\n",
    "        \"extracted_data\": {}\n",
    "    }\n"
   ],
   "id": "6648af2ad9a9cabe",
   "outputs": [],
   "execution_count": 263
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.256588Z",
     "start_time": "2024-11-25T11:54:55.250869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_flow(model, vector_store, expected_responses):\n",
    "    \"\"\"\n",
    "    Handles the conversation to collect required fields, address predefined questions, and clean memory afterward.\n",
    "    \"\"\"\n",
    "    global memory_state  # Ensure memory state can be reset if needed\n",
    "\n",
    "    print(\"Agent: Welcome! Let’s start by gathering some details.\")\n",
    "\n",
    "    while memory_state[\"missing_fields\"]:\n",
    "        # Step 1: Focus on the next missing field\n",
    "        missing_field = memory_state[\"missing_fields\"][0]\n",
    "        prompt = get_dynamic_prompt(missing_field)\n",
    "        print(f\"Agent: {prompt}\")\n",
    "\n",
    "        # Step 2: Capture user response\n",
    "        user_input = input(\"Your response: \").strip()\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"done\"]:\n",
    "            print(\"Agent: Thank you for the information. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Step 3: Fallback for predefined questions\n",
    "        response = query_matching(user_input, vector_store, expected_responses, model)\n",
    "        if \"Sorry\" not in response:  # Valid predefined match\n",
    "            print(\"Agent:\", response)\n",
    "            continue\n",
    "\n",
    "        # Step 4: Validate and update memory state for missing fields\n",
    "        if validate_response(user_input, missing_field):\n",
    "            memory_state[\"extracted_data\"][missing_field] = user_input\n",
    "            memory_state[\"missing_fields\"].remove(missing_field)\n",
    "            print(f\"Agent: Got it! {missing_field} updated to: {user_input}.\")\n",
    "        else:\n",
    "            print(\"Agent: That doesn’t seem right. Could you clarify?\")\n",
    "            continue\n",
    "\n",
    "    # Step 5: Provide next steps and reset memory\n",
    "    print(\"Agent: All required fields have been collected successfully!\")\n",
    "    print(f\"Collected Information: {memory_state['extracted_data']}\")\n",
    "    suggest_next_steps()\n",
    "    clean_memory()\n",
    "    print(\"Agent: Memory cleaned. Ready for a new conversation.\")\n"
   ],
   "id": "85c81adbd271b1a3",
   "outputs": [],
   "execution_count": 264
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.265298Z",
     "start_time": "2024-11-25T11:54:55.262172Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f4a18c83d0201404",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.275448Z",
     "start_time": "2024-11-25T11:54:55.270971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize memory state\n",
    "memory_state = {\n",
    "    \"conversation_started\": False,\n",
    "    \"missing_fields\": [\"company_size\", \"industry\", \"location\", \"job_roles\"],\n",
    "    \"extracted_data\": {}\n",
    "}\n",
    "\n",
    "# Start the conversation\n",
    "# chat_flow(model, vector_store, responses)"
   ],
   "id": "da3db1ee7b31bd1d",
   "outputs": [],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.754827Z",
     "start_time": "2024-11-25T11:54:55.283862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Initialize memory state\n",
    "memory_state = {\n",
    "    \"conversation_started\": False,\n",
    "    \"missing_fields\": [\"company_size\", \"industry\", \"location\", \"job_roles\"],\n",
    "    \"extracted_data\": {}\n",
    "}\n",
    "\n",
    "# Streamlit app configuration\n",
    "st.title(\"AI Lead Generation Assistant\")\n",
    "st.sidebar.title(\"Conversation Settings\")\n",
    "start_new_session = st.sidebar.button(\"Start New Session\")\n",
    "\n",
    "\n",
    "# Clean memory if a new session is started\n",
    "if start_new_session or not memory_state[\"conversation_started\"]:\n",
    "    memory_state = {\n",
    "        \"conversation_started\": True,\n",
    "        \"missing_fields\": [\"company_size\", \"industry\", \"location\", \"job_roles\"],\n",
    "        \"extracted_data\": {}\n",
    "    }\n",
    "    st.session_state[\"conversation_history\"] = []\n",
    "\n",
    "\n",
    "# Chat display\n",
    "st.write(\"Welcome! Let’s start by gathering some details.\")\n",
    "if \"conversation_history\" not in st.session_state:\n",
    "    st.session_state[\"conversation_history\"] = []\n",
    "\n",
    "for message in st.session_state[\"conversation_history\"]:\n",
    "    st.write(message)"
   ],
   "id": "635521b3a690774b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 13:54:55.551 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Session state does not function when running a script without `streamlit run`\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:54:55.771460Z",
     "start_time": "2024-11-25T11:54:55.760645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input box\n",
    "user_input = st.text_input(\"Your response:\", key=\"user_input\")\n",
    "if st.button(\"Send\"):\n",
    "    if user_input.strip():\n",
    "        # Add user input to the conversation\n",
    "        st.session_state[\"conversation_history\"].append(f\"You: {user_input}\")\n",
    "\n",
    "        # Check for predefined responses\n",
    "        response = query_matching(user_input, vector_store, responses, model)\n",
    "        if \"Sorry\" not in response:  # Valid predefined match\n",
    "            st.session_state[\"conversation_history\"].append(f\"Agent: {response}\")\n",
    "        else:\n",
    "            # Handle missing fields\n",
    "            if memory_state[\"missing_fields\"]:\n",
    "                missing_field = memory_state[\"missing_fields\"][0]\n",
    "                if validate_response(user_input, missing_field):\n",
    "                    memory_state[\"extracted_data\"][missing_field] = user_input\n",
    "                    memory_state[\"missing_fields\"].remove(missing_field)\n",
    "                    st.session_state[\"conversation_history\"].append(\n",
    "                        f\"Agent: Got it! {missing_field} updated to: {user_input}.\"\n",
    "                    )\n",
    "                else:\n",
    "                    st.session_state[\"conversation_history\"].append(\n",
    "                        \"Agent: That doesn’t seem right. Could you clarify?\"\n",
    "                    )\n",
    "            else:\n",
    "                # Suggest next steps\n",
    "                suggest_next_steps()\n",
    "                st.session_state[\"conversation_history\"].append(\n",
    "                    \"Agent: All required fields have been collected successfully!\"\n",
    "                )\n",
    "                st.session_state[\"conversation_history\"].append(\n",
    "                    \"Agent: Memory cleaned. Ready for a new conversation.\"\n",
    "                )\n",
    "                clean_memory()\n"
   ],
   "id": "3afa309162612928",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-25 13:54:55.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "execution_count": 267
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
